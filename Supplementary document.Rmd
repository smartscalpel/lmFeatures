---
title: "Supplementary document"
author: "Anatoly Sorokin"
date: "6/15/2017"
output:
  pdf_document:
    keep_tex: yes
    number_sections: yes
    highlight: tango
    toc: yes
    include:
      in_header: myStyle.sty
params:
  format: !r if(opts_knit$get("rmarkdown.pandoc.to") == 'html') c('screen', 'print')
    else 'print'
  version: !r if(nchar(Sys.which("git"))) system("git describe --long --dirty --abbrev=10  --tags  --always",
    intern=TRUE) else date()
---
```{r loadPackages, include=FALSE, cache=FALSE}
## load additional packages in this chunk
library(pander)
library(knitr)
library('Matrix')
library(ggplot2)
library(data.table)
library(plyr)
library(xtable)
library("FactoMineR")
library(cluster)
library(dendextend)
library(factoextra)
library(corrplot)
library("PerformanceAnalytics")
library(dynamicTreeCut)
library(xcms)
library(RColorBrewer)
library(ggrepel)
library(IRanges)
```

```{r setup, include=FALSE, cache=FALSE}
## This chunk should contain global configuration commands.
## Use this to set knitr options and related things. Everything
## in this chunk will be included in an appendix to document the
## configuration used.
#output <- opts_knit$get("rmarkdown.pandoc.to")

## By default R code is only included in HTML versions of the report
## (where it can be collapsed). You can generate a PDF version
## using rmarkdown::pdf_document to get a copy for print. Extensive
## chunks of R code may or may not be desired in /hat setting. If you
## want them simply change the following arguments to `echo = TRUE`.
## In either case the default can be overwritten for individual chunks.
#opts_chunk$set(echo = output=="html")
#opts_chunk$set(warning = output=="html")
#opts_chunk$set(message = output=="html")

## Cache options
opts_chunk$set(cache=TRUE)

## Figure options
## Set default figure format
#options(reportmd.figure.format=params$format)

## Set 'hide.fig.code' to FALSE to include code chunks that
## produce Figures in the output. Note that this affects all chunks
## that provide a figure caption.
opts_chunk$set(hold=TRUE, hide.fig.code=FALSE)

## Set up default plotting options for different formats.
## These can be overwritten for individual chunks
#interactiveFig()
#screenFig()
#printFig()

## Pander options
panderOptions("digits", 3)
panderOptions("table.split.table", 160)

## Configure Figure and Table lables
#options(figcap.prefix = "Figure", figcap.sep = ":", figcap.prefix.highlight = "**")
#options(tabcap.prefix = "Table", tabcap.sep = ":", tabcap.prefix.highlight = "**")

## Install required knitr hooks
#installHooks()
```

```{r functions, include=FALSE}
## Custom functions used in the analysis should go into this chunk.
## They will be listed in their own section of the appendix.
makePeaks<-function(.xcms){
  # this function converts XCMSRaw data into mz table
    sel <- profRange(.xcms)
    peaks<-data.frame(mz=100.0,
                      intensity=1.0e6,
                      ion=NA,
                      MP=NA,
                      time=0.0,
                      scan=1,
                      delta=NA,
                      adduct=NA)[FALSE,]
    l<-list()
    l<-lapply(sel$scanidx,function(i){
        scan <- as.data.table(getScan(xraw, sel$scanidx[i], sel$mzrange))
        p<-scan
        p$ion<-NA
        p$time<-xraw@scantime[i]
        p$scan<-i
        return(p)
    })
    peaks<-as.data.table(ldply(l,rbind))
    return(peaks)
}
getScanPlot<-function(mz1){
  mzp<-mz1
  mzp[,lab:=paste(round(mz,4))]
  mzp[order(intensity,decreasing = TRUE)[-c(1:10)],lab:='']
  p<-ggplot(mzp, aes(x=mz,yend=0,xend=mz, y=intensity)) +
    geom_segment()+geom_point(size=0.15) + #scale_y_log10()+
    geom_text_repel(aes(x = mz,y=intensity,label=lab))+
    theme(legend.position="none")
  return(p)
}

# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
# 
# Code is taken from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_%28ggplot2%29/
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

get_Rle<-function(.scan,.max){
    require(IRanges)
  xf <- rep(0, .max)
  xf[.scan] <- 1
  Rle(xf) -> r
  return(r)
}

get_runLen <- function(.scan, .max) {
  r<-get_Rle(.scan,.max)
  return(runLength(r)[which(runValue(r)==1)])
}


```

```{r set.constants,include=FALSE}
  FName<-'0_00_HealthyBrain_0_FT100k.raw.mzXML'
  path<-'/Users/lptolik/Yandex.Disk.localized/BDmzXML/FT_centroid/'
  ppm<-50
  .pal <- brewer.pal(12,'Paired')
```

# Load the data

Thermo RAW files were converted into mzXML by ReAdW.201510.xcalibur.exe 
application. After that we load mzXML file into R with help of XCMS package and
convert it into MZ table:
```{r read.file, cache=TRUE}
  xraw <- xcmsRaw(paste0(path,FName))
  p<-makePeaks(xraw)
  scanLen <- max(p$scan)
```

As a result we have table with 5 columns: `r paste0('"',names(p),'"')` to store 
m/z, intensity, time of scan and its number. Column "ion" is reserved for ID of
the feature, obtained with further analysis.

# Feature selection

The algorithm process data in the MZ table in intensity descending order, so 
whenever it stops we can be sure that we identify most important features in the
data. 

At the first step algorithm selects row with highest intensity, which is not 
assigned to any feature yet, and take its m/z value as proposed feature position:

```{r get.mz}
  idx<-which(is.na(p$ion))
  cP<-which.max(p$intensity[idx])
  ionI<-idx[cP]
  maxMZ<-p$mz[ionI]
```

The selected row represents the peak with m/z=`r round(maxMZ,4)` of the scan 
N=`r p$scan[ionI]` taken at time `r round(p$time[ionI],1)` sec: 

```{r ion.plots,fig.width=8.5,fig.height=4.5,results='asis',cache=FALSE}
print(getScanPlot(p[scan==p$scan[ionI]]))
```

Now we collect all signals in the vicinity (50 ppm) of the selected m/z value and analyze
how they drift with time:

```{r get.subset}
  idx <- which(abs(p$mz - maxMZ) < (ppm * 1e-6 * maxMZ))
  p. <- p[idx, ]
```

To separate feature from surrounding noise we cluster data in m/z domain by 
hierarchical Ward clustering and select the most stable clusters with 
dynamicTreeCut:

```{r cluster.mz}
  dissim1 = dist(p.$mz)
  dendro1 <- hclust(d = dissim1, method = 'ward.D2')
  ct1 <- cutreeDynamic(
    dendro1,
    cutHeight = NULL,
    minClusterSize = 30,
    method = "hybrid",
    deepSplit = 0,
    pamStage = TRUE,
    distM = as.matrix(dissim1),
    maxPamDist = 0,
    verbose = 0
  )
  cct1 <- ct1[which.max(p.$intensity)]
  id.1 <- idx[ct1 == cct1]
  mz1 <- median(p$mz[id.1])
  p.$color<-.pal[ct1+1]
  rl <- get_runLen(p$scan[id.1], scanLen)
  p1<-qplot(time,intensity,data = p.,main=paste0('mz',maxMZ),log='y',color=color)
  p2<-qplot(time,mz,data = p.,color=color)
  p3<-qplot(mz,intensity,data = p.,color=color)
  print(multiplot(p1, p2, p3, cols=1))
  
```

It could be seen that selected m/z value forms a well separated cluster as in m/z 
as in intensity domain, but this is not always the case. There are peaks which 
could not be separated by such procedure, for example:

It could be seen that even in this case each feature visually represents well 
separated line on the time vs m/z plot. So we can extract distinct features by 
fitting data from cluster containing peak of highest intensity to the linear 
function:

```{r fit.lin}
  l<-lm(mz ~ time, data = p[id.1, ])
if (all(!is.na(l$coefficients))) {
  op <- par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
  plot(l)
  par(op)
}
```

Now to incorporate to the feature all points, that form the line even if they 
appear in different cluster we predict linear value for each point in the 
selected interval and filter out all points with residuals higher than two 
standard deviations:
```{r filter.lm}
if (all(!is.na(l$coefficients))) {
  range(l$residuals[abs(rstandard(l)) <= 2]) -> bnd
  pl <- predict(l, p.)
  rl <- p.$mz - pl
  idL <- which(rl >= bnd[1] & rl <= bnd[2])
  p5 = qplot(
          time,
          mz,
          data = p.[idL],
          color = color,
          xlim = range(p.$time),
          ylim = range(p.$mz)
  )
  p6 = qplot(time,
          mz,
          data = p.,
          color = color) +
      geom_abline(intercept = l$coefficients[1],
          slope = l$coefficients[2])
  print(multiplot(p5, p6, cols = 1))
}
```

The fitted line will change due to rearrangement of the feature point list, so 
we will repeat this step untill it converges, but no more than 50 times.

Final step of the algorithm is the quality control. The feature could be too wide
in m/z domain or it could eventually consists of several close crests, it could
contains several points from the same scan. 
As we looking for continious features and rely on linear regression we will 
remove from the list all features which is too short to produse reliable 
regression. Only features wich contains more than 300 points in of more than 
100 consequtive scans will be preserved. High intensity bursting ions should be
analysed separately.



# Appendix {.tabset}
## Custom Functions
```{r functions, eval=FALSE, include=TRUE}
```

## Version
### Document version
```{r docVersion, echo=FALSE, results='asis', cache=FALSE}
cat(params$version,'\n',format(Sys.time(), "%d.%m.%Y"))

```

### Session Info
```{r sessionInfo, echo=FALSE, results='asis', class='text', warning=FALSE}
pander(devtools::session_info())
```





